#!/usr/bin/env python
# fetch_ikyu_reviews.py
# ä¸€ä¼‘/Yahoo!ãƒˆãƒ©ãƒ™ãƒ«ã®å£ã‚³ãƒŸ å¹³å‡/ä»¶æ•°ã‚’å–å¾—ã—ã€data/ota_facility_meta.json ã«ã€Œå®‰å…¨ãƒãƒ¼ã‚¸ã€ä¿å­˜
# å„ªå…ˆ: ikyu_url / ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: yahoo_travel_urlï¼ˆå€¤ã¯å®Ÿå‹™ä¸ŠåŒç­‰ã®ãŸã‚ ikyu ãƒ–ãƒ­ãƒƒã‚¯ã«æ ¼ç´ï¼‰

import os, json, re
import datetime as dt
from typing import Dict, Any, Optional, Tuple
from playwright.sync_api import sync_playwright

ROOT = os.path.dirname(os.path.abspath(__file__))
DATA = os.path.join(ROOT, "data")
MASTER_PATH = os.path.join(DATA, "hotel_master.json")
META_PATH   = os.path.join(DATA, "ota_facility_meta.json")

# ---- å¾…æ©Ÿãƒ»æŒ™å‹•è¨­å®šï¼ˆå…ˆæ–¹è² è·ã‚’ä¸‹ã’ã‚‹ & é…å»¶æç”»å¯¾ç­–ï¼‰ ----
WAIT_MS   = 3500   # åˆæœŸæç”»å¾…æ©Ÿ (â†‘)
DELAY_MS  = 1200   # ãƒ›ãƒ†ãƒ«é–“ã‚¦ã‚§ã‚¤ãƒˆ
HEADLESS  = True
MAX_RETRY = 3
BASE_WAIT_MS = 800 # ãƒªãƒˆãƒ©ã‚¤ãƒãƒƒã‚¯ã‚ªãƒ•åŸºæº–

# ---- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----
FW_MAP = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼Œï¼ï¼ˆï¼‰", "0123456789,.()")

def to_halfwidth(s: str) -> str:
    return s.translate(FW_MAP)

def iso_utc_now() -> str:
    return dt.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

def load_json(path: str) -> Any:
    if not os.path.exists(path): return None
    with open(path, "r", encoding="utf-8") as f: return json.load(f)

def dump_json(path: str, obj: Any):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)

def jnum_to_int(s: str) -> Optional[int]:
    try:
        s = to_halfwidth(s).replace(",", "").strip()
        return int(s)
    except Exception:
        return None

def jnum_to_float(s: str) -> Optional[float]:
    try:
        s = to_halfwidth(s).replace(",", "").strip()
        return float(s)
    except Exception:
        return None

# ---- æŠ½å‡ºï¼ˆå„ªå…ˆï¼šJSON-LDã€æ¬¡ç‚¹ï¼šãƒ†ã‚­ã‚¹ãƒˆï¼‰ ----
def extract_from_ldjson(html: str) -> Optional[Tuple[Optional[float], Optional[int]]]:
    """application/ld+json ã‹ã‚‰ ratingValue ã¨ reviewCount/ratingCount ã‚’å–å¾—"""
    for m in re.finditer(
        r'<script[^>]+type=["\']application/ld\+json["\'][^>]*>(.*?)</script>',
        html, re.S | re.I
    ):
        block_txt = m.group(1)
        try:
            block = json.loads(block_txt)
        except Exception:
            continue

        blocks = block if isinstance(block, list) else [block]
        for b in blocks:
            if not isinstance(b, dict):
                continue
            agg = b.get("aggregateRating")
            if not isinstance(agg, dict):
                continue

            rv = agg.get("ratingValue")
            rc = agg.get("reviewCount")
            if rc is None:
                rc = agg.get("ratingCount")  # â† Yahooå¯¾ç­–

            rating = jnum_to_float(str(rv)) if rv is not None else None
            count  = jnum_to_int(str(rc))   if rc is not None else None

            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆè©•ä¾¡ã¯ 0ã€œ5 ã®ã¿æœ‰åŠ¹ï¼‰
            if rating is not None and not (0 <= rating <= 5):
                rating = None

            if rating is not None or count is not None:
                return (rating, count)
    return None

def extract_from_text(html: str) -> Optional[Tuple[Optional[float], Optional[int]]]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å …ç‰¢ã«æŠ½å‡ºã€‚
    - è©•ä¾¡ã¯ 0ã€œ5 ã®å°æ•°ã®ã¿ï¼ˆå¹´å·ãƒ»IDã‚’é™¤å¤–ï¼‰
    - ä»¶æ•°ã¯ã€Œâ—¯â—¯ä»¶ã€ã®ã¿
    - ã€Œç·åˆå¾—ç‚¹ã€ã€Œå£ã‚³ãƒŸã€ã€Œã‚¯ãƒã‚³ãƒŸã€ã€Œãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã€Œè©•ä¾¡ã€è¿‘å‚ã‚’å„ªå…ˆ
    """
    text = re.sub(r"<[^>]+>", " ", html)
    text = to_halfwidth(text)
    text = re.sub(r"\s+", " ", text)

    anchors = ["ç·åˆå¾—ç‚¹", "å£ã‚³ãƒŸ", "ã‚¯ãƒã‚³ãƒŸ", "ãƒ¬ãƒ“ãƒ¥ãƒ¼", "è©•ä¾¡"]
    near_chunks = []
    for kw in anchors:
        for m in re.finditer(re.escape(kw), text):
            i = m.start()
            near_chunks.append(text[max(0, i-220): i+260])
    if not near_chunks:
        near_chunks = [text]

    # ä»£è¡¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼šç·åˆå¾—ç‚¹ 4.04 ï¼ˆ25ä»¶ï¼‰
    pat_rating1 = re.compile(r"(?:ç·åˆå¾—ç‚¹|è©•ä¾¡)\s*[:ï¼š]?\s*([0-5](?:\.\d{1,2})?)")
    pat_rating2 = re.compile(r"([0-5](?:\.\d{1,2})?)\s*(?:ç‚¹|/5|ï¼5|5ç‚¹)")
    pat_count   = re.compile(r"\(\s*(\d{1,3}(?:,\d{3})*)\s*ä»¶\s*\)|(\d{1,3}(?:,\d{3})*)\s*ä»¶")

    def find_rating(chunk: str) -> Optional[float]:
        for pat in (pat_rating1, pat_rating2):
            m = pat.search(chunk)
            if m:
                v = jnum_to_float(m.group(1))
                if v is not None and 0 <= v <= 5:
                    return v
        return None

    def find_count(chunk: str) -> Optional[int]:
        m = pat_count.search(chunk)
        if m:
            g = m.group(1) or m.group(2)
            return jnum_to_int(g)
        return None

    rating = None
    count  = None
    for ch in near_chunks:
        if rating is None:
            rating = find_rating(ch)
        if count is None:
            count = find_count(ch)
        if rating is not None or count is not None:
            break

    # æœ€å¾Œã®ä¿é™ºï¼šå…¨æ–‡ã‹ã‚‰
    if rating is None:
        rating = find_rating(text)
    if count is None:
        count = find_count(text)

    if rating is not None and not (0 <= rating <= 5):
        rating = None

    return (rating, count) if (rating is not None or count is not None) else None

def safe_merge(meta: Dict[str, Any], updates: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
    out = meta.copy() if isinstance(meta, dict) else {}
    hotels = out.setdefault("hotels", {})
    for hid, v in updates.items():
        hotels.setdefault(hid, {})
        hotels[hid]["ikyu"] = {
            "review_avg":   v.get("review_avg"),
            "review_count": v.get("review_count"),
        }
    out["last_updated"] = iso_utc_now()
    return out

# ---- å–å¾—ï¼ˆå°ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰ ----
def try_get_content(page, url: str) -> Optional[str]:
    for i in range(MAX_RETRY):
        try:
            # é…å»¶æç”»ãŒã‚ã‚‹ãŸã‚ "networkidle" ã‚’ä½¿ç”¨
            page.goto(url, wait_until="networkidle", timeout=45000)
            page.wait_for_timeout(WAIT_MS)
            return page.content()
        except Exception as e:
            w = BASE_WAIT_MS * (2 ** i)
            print(f"âš ï¸ gotoå¤±æ•—({i+1}/{MAX_RETRY}) {e} â†’ {w}mså¾…æ©Ÿã—ã¦å†è©¦è¡Œ")
            page.wait_for_timeout(w)
    return None

def pick_target_url(h: Dict[str, Any]) -> Optional[Tuple[str, str]]:
    """
    å„ªå…ˆ: ikyu_url / ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: yahoo_travel_url
    æˆ»ã‚Šå€¤: (url, source_label) ä¾‹: ("https://www.ikyu.com/...", "ikyu")
    """
    ikyu = (h.get("ikyu_url") or "").strip()
    if ikyu:
        return ikyu, "ikyu"
    yahoo = (h.get("yahoo_travel_url") or "").strip()
    if yahoo:
        return yahoo, "yahoo"
    return None

def main():
    master = load_json(MASTER_PATH)
    if not master or "hotels" not in master:
        raise SystemExit("âŒ data/hotel_master.json ãŒèª­ã‚ã¾ã›ã‚“")

    # å¯¾è±¡æŠ½å‡ºï¼ˆenabled ã‹ã¤ ikyu_url or yahoo_travel_url ã®ã©ã¡ã‚‰ã‹ãŒã‚ã‚‹ï¼‰
    targets = []
    for h in master["hotels"]:
        if not h.get("enabled"):
            continue
        picked = pick_target_url(h)
        if picked:
            url, src = picked
            targets.append({"id": h["id"], "url": url, "src": src})

    if not targets:
        print("â„¹ï¸ å¯¾è±¡ãƒ›ãƒ†ãƒ«ï¼ˆikyu_url/yahoo_travel_urlã‚ã‚Šï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return

    results: Dict[str, Dict[str, Any]] = {}
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=HEADLESS)
        ctx = browser.new_context(
            locale="ja-JP",
            user_agent=("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) "
                        "Chrome/124.0 Safari/537.36")
        )
        page = ctx.new_page()

        for t in targets:
            url, hid, src = t["url"], t["id"], t["src"]
            try:
                html = try_get_content(page, url)
                if not html:
                    print(f"âš ï¸ {hid}: å–å¾—ã§ããšï¼ˆãƒªãƒˆãƒ©ã‚¤å°½ãï¼‰ from={src} {url}")
                else:
                    pair = extract_from_ldjson(html) or extract_from_text(html)
                    if pair:
                        rating, count = pair
                        r = float(rating) if isinstance(rating, (int, float)) else None
                        c = int(count)    if isinstance(count, int) else None
                        if r is not None or c is not None:
                            results[hid] = {"review_avg": r, "review_count": c}
                            print(f"âœ… {hid}: rating={r} count={c} from={src} {url}")
                        else:
                            print(f"âš ï¸ {hid}: æ•°å€¤ãŒå–å¾—ã§ããš from={src} {url}")
                    else:
                        print(f"âš ï¸ {hid}: ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸ä¸€è‡´ã§æŠ½å‡ºä¸å¯ from={src} {url}")
            except Exception as e:
                print(f"âš ï¸ {hid}: ã‚¨ãƒ©ãƒ¼ {e} from={src} {url}")
            finally:
                page.wait_for_timeout(DELAY_MS)

        ctx.close()
        browser.close()

    if not results:
        print("â„¹ï¸ å–å¾—çµæœãŒç©ºï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
        return

    meta = load_json(META_PATH) or {}
    merged = safe_merge(meta, results)
    dump_json(META_PATH, merged)
    print(f"ğŸ“ wrote {META_PATH}  (updated_hotels={len(results)})")

if __name__ == "__main__":
    main()
