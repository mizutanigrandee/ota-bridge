#!/usr/bin/env python
# fetch_ikyu_reviews.py
# ä¸€ä¼‘ã®å£ã‚³ãƒŸ å¹³å‡/ä»¶æ•°ã‚’å–å¾—ã—ã€data/ota_facility_meta.json ã«ã€Œå®‰å…¨ãƒãƒ¼ã‚¸ã€ä¿å­˜

import os, json, re
import datetime as dt
from typing import Dict, Any, Optional, Tuple
from playwright.sync_api import sync_playwright

ROOT = os.path.dirname(os.path.abspath(__file__))
DATA = os.path.join(ROOT, "data")
MASTER_PATH = os.path.join(DATA, "hotel_master.json")
META_PATH   = os.path.join(DATA, "ota_facility_meta.json")

# ---- å¾…æ©Ÿãƒ»æŒ™å‹•è¨­å®šï¼ˆå…ˆæ–¹è² è·ã‚’ä¸‹ã’ã‚‹ï¼‰ ----
WAIT_MS   = 2500   # åˆæœŸæç”»å¾…æ©Ÿ
DELAY_MS  = 1200   # ãƒ›ãƒ†ãƒ«é–“ã‚¦ã‚§ã‚¤ãƒˆ
HEADLESS  = True
MAX_RETRY = 3
BASE_WAIT_MS = 800 # ãƒªãƒˆãƒ©ã‚¤ãƒãƒƒã‚¯ã‚ªãƒ•åŸºæº–

# ---- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----
def iso_utc_now() -> str:
    return dt.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

def load_json(path: str) -> Any:
    if not os.path.exists(path): return None
    with open(path, "r", encoding="utf-8") as f: return json.load(f)

def dump_json(path: str, obj: Any):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)

def jnum_to_int(s: str) -> Optional[int]:
    try:
        s = s.replace(",", "").strip()
        return int(s)
    except Exception:
        return None

def jnum_to_float(s: str) -> Optional[float]:
    try:
        s = s.replace(",", "").strip()
        return float(s)
    except Exception:
        return None

# ---- æŠ½å‡ºï¼ˆå„ªå…ˆï¼šJSON-LDã€æ¬¡ç‚¹ï¼šãƒ†ã‚­ã‚¹ãƒˆï¼‰ ----
def extract_from_ldjson(html: str) -> Optional[Tuple[Optional[float], Optional[int]]]:
    for m in re.finditer(
        r'<script[^>]+type=["\']application/ld\+json["\'][^>]*>(.*?)</script>',
        html, re.S | re.I
    ):
        try:
            block = json.loads(m.group(1))
            blocks = block if isinstance(block, list) else [block]
            for b in blocks:
                agg = b.get("aggregateRating") if isinstance(b, dict) else None
                if isinstance(agg, dict):
                    rv = agg.get("ratingValue")
                    rc = agg.get("reviewCount")
                    rating = jnum_to_float(str(rv)) if rv is not None else None
                    count  = jnum_to_int(str(rc))   if rc is not None else None
                    if rating is not None or count is not None:
                        return (rating, count)
        except Exception:
            continue
    return None

def extract_from_text(html: str) -> Optional[Tuple[Optional[float], Optional[int]]]:
    text = re.sub(r"<[^>]+>", " ", html)
    anchors = ["å£ã‚³ãƒŸ", "ã‚¯ãƒã‚³ãƒŸ", "ãƒ¬ãƒ“ãƒ¥ãƒ¼"]
    for kw in anchors:
        idx = text.find(kw)
        if idx != -1:
            win = text[max(0, idx-120): idx+200]
            m_rating = re.search(r"(\d+(?:\.\d+)?)", win)
            m_count  = re.search(r"(\d{1,3}(?:,\d{3})*)\s*ä»¶", win)
            rating = jnum_to_float(m_rating.group(1)) if m_rating else None
            count  = jnum_to_int(m_count.group(1)) if m_count  else None
            if rating is not None or count is not None:
                return (rating, count)
    # æœ€å¾Œã®ä¿é™ºï¼ˆèª¤æ¤œå‡ºã®æã‚Œã‚ã‚Šï¼‰
    m_count  = re.search(r"(\d{1,3}(?:,\d{3})*)\s*ä»¶", text)
    m_rating = re.search(r"(\d+(?:\.\d+)?)", text)
    rating = jnum_to_float(m_rating.group(1)) if m_rating else None
    count  = jnum_to_int(m_count.group(1)) if m_count  else None
    return (rating, count) if (rating is not None or count is not None) else None

def safe_merge(meta: Dict[str, Any], updates: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
    out = meta.copy() if isinstance(meta, dict) else {}
    hotels = out.setdefault("hotels", {})
    for hid, v in updates.items():
        hotels.setdefault(hid, {})
        hotels[hid]["ikyu"] = {
            "review_avg":   v.get("review_avg"),
            "review_count": v.get("review_count"),
        }
    out["last_updated"] = iso_utc_now()
    return out

# ---- å–å¾—ï¼ˆå°ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰ ----
def try_get_content(page, url: str) -> Optional[str]:
    for i in range(MAX_RETRY):
        try:
            page.goto(url, wait_until="load", timeout=45000)
            page.wait_for_timeout(WAIT_MS)
            return page.content()
        except Exception as e:
            w = BASE_WAIT_MS * (2 ** i)
            print(f"âš ï¸ gotoå¤±æ•—({i+1}/{MAX_RETRY}) {e} â†’ {w}mså¾…æ©Ÿã—ã¦å†è©¦è¡Œ")
            page.wait_for_timeout(w)
    return None

def main():
    master = load_json(MASTER_PATH)
    if not master or "hotels" not in master:
        raise SystemExit("âŒ data/hotel_master.json ãŒèª­ã‚ã¾ã›ã‚“")

    # å¯¾è±¡æŠ½å‡ºï¼ˆenabled & ikyu_urlã‚ã‚Šï¼‰
    targets = []
    for h in master["hotels"]:
        url = (h.get("ikyu_url") or "").strip()
        if h.get("enabled") and url:
            targets.append({"id": h["id"], "url": url})

    if not targets:
        print("â„¹ï¸ å¯¾è±¡ãƒ›ãƒ†ãƒ«ï¼ˆikyu_urlã‚ã‚Šï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return

    results: Dict[str, Dict[str, Any]] = {}
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=HEADLESS)
        ctx = browser.new_context(
            locale="ja-JP",
            user_agent=("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) "
                        "Chrome/124.0 Safari/537.36")
        )
        page = ctx.new_page()

        for t in targets:
            url, hid = t["url"], t["id"]
            try:
                html = try_get_content(page, url)
                if not html:
                    print(f"âš ï¸ {hid}: å–å¾—ã§ããšï¼ˆãƒªãƒˆãƒ©ã‚¤å°½ãï¼‰")
                else:
                    pair = extract_from_ldjson(html) or extract_from_text(html)
                    if pair:
                        rating, count = pair
                        r = float(rating) if isinstance(rating, (int, float)) else None
                        c = int(count) if isinstance(count, int) else None
                        if r is not None or c is not None:
                            results[hid] = {"review_avg": r, "review_count": c}
                            print(f"âœ… {hid}: ikyu rating={r} count={c}")
                    else:
                        print(f"âš ï¸ {hid}: ãƒ‘ã‚¿ãƒ¼ãƒ³ä¸ä¸€è‡´ã§æŠ½å‡ºä¸å¯")
            except Exception as e:
                print(f"âš ï¸ {hid}: ã‚¨ãƒ©ãƒ¼ {e}")
            finally:
                page.wait_for_timeout(DELAY_MS)

        ctx.close()
        browser.close()

    if not results:
        print("â„¹ï¸ å–å¾—çµæœãŒç©ºï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
        return

    meta = load_json(META_PATH) or {}
    merged = safe_merge(meta, results)
    dump_json(META_PATH, merged)
    print(f"ğŸ“ wrote {META_PATH}  (updated_hotels={len(results)})")

if __name__ == "__main__":
    main()
